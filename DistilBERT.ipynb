{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharanya-Parimanoharan/AI-Generated-Text-Detection/blob/main/DistilBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fJKsoSaYe2xw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVsc_4sWe45y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve,roc_auc_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-2JJEKZe606"
      },
      "outputs": [],
      "source": [
        "# Load your dataset (data_2.csv)\n",
        "df = pd.read_csv(\"drive/MyDrive/data_2.csv\")\n",
        "#dataset=load_dataset(\"artem9k/ai-text-detection-pile\")\n",
        "#df=pd.DataFrame(dataset['train'])\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czYOEDAFe9B5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Data preprocessing\n",
        "# Remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "df['text']= df['text'].apply(remove_punctuation)\n",
        "\n",
        "# Handle missing values\n",
        "df.dropna(inplace=True)\n",
        "df['text'].fillna(\"NA\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP-LRTS0fCAk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert labels to integers (assuming 'AI' is positive and others are negative)\n",
        "df[\"label_int\"] = np.where(df[\"label\"] == '\"AI\"', 1, 0)\n",
        "\n",
        "\n",
        "# split train dataset into train, validation and test sets\n",
        "X_train, temp_text, y_train, temp_labels = train_test_split(df['text'], df['label_int'],\n",
        "                                                                    random_state=2018,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['label_int'])\n",
        "\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2018,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc2cpjtMfi25"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load DistilBERT tokenizer and model\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification\n",
        "\n",
        "# Tokenize and preprocess the data\n",
        "max_length = 128  # You can adjust this based on your dataset\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJQojFgvfjUH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Tokenize the training data\n",
        "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=max_length, return_tensors='pt', add_special_tokens=True)\n",
        "train_labels = torch.tensor(list(y_train))\n",
        "train_tokens = tokenizer.convert_ids_to_tokens(train_encodings[\"input_ids\"][0])\n",
        "print(train_tokens)\n",
        "\n",
        "# Tokenize the testing data\n",
        "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=max_length, return_tensors='pt', add_special_tokens=True)\n",
        "test_labels = torch.tensor(list(y_test))\n",
        "\n",
        "# Tokenize the val data\n",
        "val_encodings = tokenizer(list(X_val), truncation=True, padding=True, max_length=max_length, return_tensors='pt', add_special_tokens=True)\n",
        "val_labels = torch.tensor(list(y_val))\n",
        "\n",
        "# Create DataLoader for training and testing\n",
        "train_data = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pjnKrossflu1"
      },
      "outputs": [],
      "source": [
        "# Set up optimizer and training parameters\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "epochs = 10  # You can adjust this based on your dataset\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Average training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_total_loss = 0\n",
        "    for val_batch in val_dataloader:\n",
        "        val_input_ids, val_attention_mask, val_labels = val_batch\n",
        "        val_outputs = model(val_input_ids, attention_mask=val_attention_mask, labels=val_labels)\n",
        "        val_loss = val_outputs.loss\n",
        "        val_total_loss += val_loss.item()\n",
        "\n",
        "    avg_val_loss = val_total_loss / len(val_dataloader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Average validation loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zPMe6EEQh652"
      },
      "outputs": [],
      "source": [
        "# plot training loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zdYrXG7yhx-A"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predicted_label = np.argmax(logits, axis=1).tolist()\n",
        "        true_label = labels.tolist()\n",
        "\n",
        "        # Print some batch-wise information\n",
        "        print(\"Input IDs:\", input_ids)\n",
        "        print(\"Logits:\", logits)\n",
        "        print(\"Predicted Label:\", predicted_label)\n",
        "        print(\"True Label:\", true_label)\n",
        "\n",
        "        predicted_labels.extend(predicted_label)\n",
        "        true_labels.extend(true_label)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "\n",
        "print(true_labels)\n",
        "print(predicted_labels)\n",
        "print(\"Accuracy:\", accuracy*100)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "\n",
        "     # Calculate ROC curve\n",
        "pr, tpr, thresholds = roc_curve(true_labels, predicted_labels)\n",
        "\n",
        "    # Calculate AUC\n",
        "auc_value = roc_auc_score(true_labels, predicted_labels)\n",
        "\n",
        "       # Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(pr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_value:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXcw35gPfyQn"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"classification_model\")\n",
        "tokenizer.save_pretrained(\"classification_model/tokenizer\")\n",
        "\n",
        "# Save model to Google Drive\n",
        "model.save_pretrained(\"/content/drive/MyDrive/classification_model_withloss\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/classification_model_withloss/tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tAkJnVcfyPZ"
      },
      "outputs": [],
      "source": [
        "# Load the test dataset\n",
        "test_df = pd.read_csv(\"drive/MyDrive/test_new.csv\")\n",
        "\n",
        "test_df['text'] = test_df['text'].apply(remove_punctuation)\n",
        "\n",
        "# Convert labels to integers (assuming 'AI' is positive and others are negative)\n",
        "test_df[\"label_int\"] = np.where(test_df[\"label\"] == '\"AI\"', 1, 0)\n",
        "\n",
        "\n",
        "# Split the test dataset into features and labels\n",
        "X_test = test_df[\"text\"]\n",
        "y_test = test_df[\"label_int\"]\n",
        "\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = \"/content/drive/MyDrive/classification_model_withloss\"\n",
        "tokenizer_name = \"/content/drive/MyDrive/classification_model_withloss/tokenizer\"\n",
        "\n",
        "loaded_model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
        "#loaded_tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_name)\n",
        "\n",
        "# Tokenize the testing data\n",
        "max_length = 128  # You can adjust this based on your dataset\n",
        "batch_size = 12\n",
        "\n",
        "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=max_length, return_tensors='pt', add_special_tokens=True)\n",
        "test_labels = torch.tensor(list(y_test))\n",
        "\n",
        "print(len(test_encodings['input_ids']))\n",
        "print(len(test_encodings['attention_mask']))\n",
        "\n",
        "\n",
        "# Create DataLoader for testing\n",
        "test_data = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "# Evaluation on the test set\n",
        "loaded_model.eval()\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        outputs = loaded_model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predicted_label = torch.argmax(logits, dim=1).tolist()\n",
        "        true_label = labels.tolist()\n",
        "\n",
        "        predicted_labels.extend(predicted_label)\n",
        "        true_labels.extend(true_label)\n",
        "\n",
        "np.savetxt('/content/drive/MyDrive/pred_DistilBERT.csv', predicted_labels, delimiter=',',  fmt='%.2f')\n",
        "\n",
        "\n",
        "# Calculate metrics on the test set\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "precision_ai = precision_score(true_labels, predicted_labels, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "precision_human = precision_score(true_labels, predicted_labels, pos_label=0)  # Assuming \"AI\" is the positive class\n",
        "\n",
        "recall_ai = recall_score(true_labels, predicted_labels, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "recall_human = recall_score(true_labels, predicted_labels, pos_label=0)  # Assuming \"AI\" is the positive class\n",
        "\n",
        "f1_ai = f1_score(true_labels, predicted_labels, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "f1_human = f1_score(true_labels, predicted_labels, pos_label=0)  # Assuming \"AI\" is the positive class\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy * 100)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K93hrvH0tEZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (replace with your actual values)\n",
        "ai_values = [precision_ai,recall_ai,f1_ai]\n",
        "human_values = [precision_human,recall_human,f1_human]\n",
        "\n",
        "# Metrics names\n",
        "metrics = [ 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "# Number of metrics\n",
        "num_metrics = len(metrics)\n",
        "\n",
        "# Create an array of indices for each metric\n",
        "indices = np.arange(num_metrics)\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.1\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "# Plot AI values\n",
        "ax.bar(indices, ai_values, bar_width,  color='blue',alpha=0.5)\n",
        "\n",
        "# Plot Human values\n",
        "ax.bar(indices + bar_width, human_values, bar_width, label='Human', color='orange')\n",
        "\n",
        "# Customize the plot\n",
        "ax.tick_params(axis='both', labelsize=15, labelcolor='black')\n",
        "\n",
        "# Make the axis labels (x and y) bold\n",
        "ax.xaxis.label.set_fontweight('bold')\n",
        "ax.yaxis.label.set_fontweight('bold')\n",
        "ax.set_xticks(indices + bar_width / 2)\n",
        "\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.set_ylabel('Metric Values',fontweight='bold')\n",
        "#ax.set_title('Comparison of AI and Human Performance Metrics')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LI9_qQaSTEG"
      },
      "outputs": [],
      "source": [
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Plotting\n",
        "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
        "values = [tn, fp, fn, tp]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(labels, values, color=['pink', 'yellow', 'orange', 'blue'],alpha=0.8,width=0.3)\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_ylabel('Count',fontweight='bold')\n",
        "ax.set_title('Confusion Matrix')\n",
        "\n",
        "# Add value annotations on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "ax.set_xticklabels(labels, fontweight='bold')\n",
        "\n",
        "ax.tick_params(axis='y', labelsize=20, labelcolor='black')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfYL0RR/28+Ip/b2oWCH1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}