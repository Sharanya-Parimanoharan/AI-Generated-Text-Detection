{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_fR-5AE1u-uOdzTB9lIRyc_G5EOoN8ke",
      "authorship_tag": "ABX9TyM3gOdGfTYul72Rzo0xERA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharanya-Parimanoharan/AI-Generated-Text-Detection/blob/main/BERT_CustomClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6RTsLbCitN5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "-_K1JjoCi_hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Set random seeds for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "   torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "XRVHQx67jFPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify GPU\n",
        "##device = torch.device(\"cuda\")\n",
        "# Check if CUDA (GPU) is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3C54wM26jHqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"drive/MyDrive/data_2.csv\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "BtIOU5qLjKHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#Load bert tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "label_mapping = {'\"AI\"': 1, '\"Human\"': 0}\n",
        "\n"
      ],
      "metadata": {
        "id": "1tv4GbT1jWg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
        "                                                                    random_state=2018,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2018,\n",
        "                                                                test_size=0.5,\n",
        "                                                                stratify=temp_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "Nc8ZpyKxjZIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "##pd.Series(seq_len).hist(bins = 30)\n",
        "\n",
        "# tokenize and encode sequences in the training set\n",
        "#breaks into single words and returns tokenid(integers corresponding to words)\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 25,\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 25,\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "id": "0dpU8F7xjeDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## convert lists to tensors\n",
        "label_mapping = {'\"AI\"': 1, '\"Human\"': 0}\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_labels_encoded = train_labels.map(label_mapping).tolist()\n",
        "print(train_labels_encoded)\n",
        "train_y = torch.tensor(train_labels_encoded,dtype=torch.long)\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_labels_encoded = val_labels.map(label_mapping).tolist()\n",
        "val_y = torch.tensor(val_labels_encoded,dtype=torch.long)\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_labels_encoded = test_labels.map(label_mapping)\n",
        "test_y = torch.tensor(test_labels_encoded.tolist(),dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "MH_vcXeijiCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "XPpwVoesjoog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    ##Constructor method for BERT_Arch class\n",
        "    def __init__(self, bert):\n",
        "\n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert\n",
        "\n",
        "      # dropout layer-prevents overfitting\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function is used to compute class probabilities\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model\n",
        "      ##      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "     # Pass the inputs to the BERT model\n",
        "      outputs = self.bert(sent_id, attention_mask=mask)\n",
        "\n",
        "    # Extract the 'last_hidden_state' from the BERT model's outputs\n",
        "      hidden_states = outputs.last_hidden_state\n",
        "\n",
        "    # Apply pooling or any other operations on the hidden_states if needed\n",
        "    # For example, to get a fixed-size representation (CLS token):\n",
        "      cls_token = hidden_states[:, 0, :]\n",
        "      x=self.dropout(cls_token)\n",
        "\n",
        "      x = self.fc1(x)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "vrEiDYWtjpXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = optim.AdamW(model.parameters(),\n",
        "                  lr = 1e-5)          # learning rate\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced',classes=np.unique(train_labels),y=train_labels)\n",
        "\n",
        "\n",
        "\n",
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10\n"
      ],
      "metadata": {
        "id": "BjWzIIhDjtj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "accuracies_per_epoch = []\n",
        "\n",
        "num_runs = 5\n",
        "accuracies = []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    print(f\"Run {run + 1}/{num_runs}\")\n",
        "\n",
        "    # Your training and evaluation code...\n",
        "\n",
        "    # function to train the model\n",
        "    def train():\n",
        "\n",
        "      #set the model to training mode\n",
        "      model.train()\n",
        "\n",
        "        #to keep the track of entire training dataset\n",
        "      total_loss, total_accuracy = 0, 0\n",
        "\n",
        "      # empty list to save model predictions\n",
        "      total_preds=[]\n",
        "\n",
        "      # iterate over batches\n",
        "      for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "        ##    preds = preds.long()  # Cast predictions to Long data type\n",
        "\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "        # append the model predictions\n",
        "        total_preds.append(preds)\n",
        "\n",
        "      # compute the training loss of the epoch\n",
        "      avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "      total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "      #returns the loss and predictions\n",
        "      return avg_loss, total_preds\n",
        "\n",
        "\n",
        "    # function for evaluating the model\n",
        "    def evaluate():\n",
        "\n",
        "      print(\"\\nEvaluating...\")\n",
        "\n",
        "      # deactivate dropout layers\n",
        "      model.eval()\n",
        "\n",
        "      total_loss, total_accuracy = 0, 0\n",
        "\n",
        "      # empty list to save the model predictions\n",
        "      total_preds = []\n",
        "\n",
        "      # iterate over batches\n",
        "      for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "          # Calculate elapsed time in minutes.\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "\n",
        "          # Report progress.\n",
        "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "          # model predictions\n",
        "          preds = model(sent_id, mask)\n",
        "\n",
        "          # compute the validation loss between actual and predicted values\n",
        "          loss = cross_entropy(preds,labels)\n",
        "\n",
        "          total_loss = total_loss + loss.item()\n",
        "\n",
        "          preds = preds.detach().cpu().numpy()\n",
        "\n",
        "          total_preds.append(preds)\n",
        "\n",
        "      # compute the validation loss of the epoch\n",
        "      avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "      total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "      return avg_loss, total_preds\n",
        "\n",
        "\n",
        "    # set initial loss to infinite\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "\n",
        "\n",
        "    #for each epoch\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "        #train model\n",
        "        train_loss, _ = train()\n",
        "\n",
        "        #evaluate model\n",
        "        valid_loss, _ = evaluate()\n",
        "\n",
        "        #save the best model\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "        # append training and validation loss\n",
        "        train_losses.append(train_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "\n",
        "        print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "        print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bVUQltWpjxx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   torch.save(model.state_dict(), 'drive/MyDrive/saved_weights.pt')\n"
      ],
      "metadata": {
        "id": "MmTMR7p11jQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " #load weights of best model\n",
        "path = 'drive/MyDrive/saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "   preds = model(test_seq.to(device), test_mask.to(device))\n",
        "   preds = preds.detach().cpu().numpy()\n",
        "\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "#print(classification_report(test_y, preds))\n",
        "\n",
        "\n",
        "    # Assuming true_labels and predicted_labels are your ground truth and predicted labels, respectively\n",
        "accuracy = accuracy_score(test_y, preds)\n",
        "precision = precision_score(test_y, preds, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "recall = recall_score(test_y, preds, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "f1 = f1_score(test_y, preds, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "roc_auc = roc_auc_score(test_y, preds)\n",
        "#confusion = confusion_matrix(test_y, preds, labels=['\"Human\"', '\"AI\"'])\n",
        "report = classification_report(test_y, preds)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "print(\"ROC AUC:`\", roc_auc)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(test_y)\n",
        "print()\n",
        "print(preds)\n",
        "accuracy = accuracy_score(test_y, preds)\n",
        "accuracies.append(accuracy)\n",
        "accuracies_per_epoch.append(accuracies)\n",
        "\n",
        "### Compute and print the average accuracy\n",
        "##average_accuracy = np.mean(accuracies)\n",
        "##print(f\"Average Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "#print(len(accuracies_per_epoch))\n"
      ],
      "metadata": {
        "id": "D9W3n5_313jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plot training loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(valid_losses, label='Validation Loss')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "onzBcEEcxojv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "pr, tpr, thresholds = roc_curve(test_y, preds)\n",
        "\n",
        "    # Calculate AUC\n",
        "auc_value = roc_auc_score(test_y, preds)\n",
        "\n",
        "        # Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(pr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_value:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-DwUznr7GJ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the saved weights file\n",
        "path = 'drive/MyDrive/saved_weights.pt'\n",
        "\n",
        "# Load the weights into the model\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "# Load your labeled test dataset\n",
        "test_df = pd.read_csv(\"drive/MyDrive/test.csv\")  # Replace with the actual file path\n",
        "\n",
        "# Assuming your dataset has 'text' and 'label' columns\n",
        "test_texts = test_df['text'].tolist()\n",
        "test_labels = test_df['label'].tolist()\n",
        "\n",
        "# Tokenize the test texts\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_texts,\n",
        "    max_length=25,\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_labels_encoded = [label_mapping[label] for label in test_labels]\n",
        "test_y = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
        "\n",
        "# Create a DataLoader for the test data\n",
        "test_dataset = TensorDataset(test_seq, test_mask, test_y)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Make predictions on the test set\n",
        "with torch.no_grad():\n",
        "    test_preds = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        preds = model(sent_id, mask)\n",
        "        preds = torch.argmax(preds, dim=1).cpu().numpy()\n",
        "        test_preds.extend(preds)\n",
        "\n",
        "# Convert predictions to NumPy array\n",
        "test_preds = np.array(test_preds)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_y.numpy(), test_preds)\n",
        "print(test_y.numpy())\n",
        "print(test_preds)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "K0HBRDAxsKTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some text, true labels, and predictions\n",
        "for i in range(min(25, len(test_y))):  # Print the first 5 samples\n",
        "    print(f\"Text: {test_df['text'].iloc[i]}\")\n",
        "    print(f\"True Label: {test_df['label'].iloc[i]}, Predicted Label: {test_preds[i]}\")\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "id": "xE0_5IinRnA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the saved weights file\n",
        "path = 'drive/MyDrive/saved_weights.pt'\n",
        "\n",
        "# Load the weights into the model\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "# Load your labeled test dataset\n",
        "test_df = pd.read_csv(\"drive/MyDrive/test_new.csv\")  # Replace with the actual file path\n",
        "\n",
        "# Assuming your dataset has 'text' and 'label' columns\n",
        "test_texts = test_df['text'].tolist()\n",
        "test_labels = test_df['label'].tolist()\n",
        "\n",
        "# Tokenize the test texts\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_texts,\n",
        "    max_length=25,\n",
        "    padding='max_length',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_labels_encoded = [label_mapping[label] for label in test_labels]\n",
        "test_y = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
        "\n",
        "# Create a DataLoader for the test data\n",
        "test_dataset = TensorDataset(test_seq, test_mask, test_y)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Make predictions on the test set\n",
        "with torch.no_grad():\n",
        "    test_preds = []\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        preds = model(sent_id, mask)\n",
        "        preds = torch.argmax(preds, dim=1).cpu().numpy()\n",
        "        test_preds.extend(preds)\n",
        "\n",
        "# Convert predictions to NumPy array\n",
        "test_preds = np.array(test_preds)\n",
        "\n",
        "np.savetxt('/content/drive/MyDrive/pred_BERT.csv', test_preds, delimiter=',',  fmt='%.2f')\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_y.numpy(), test_preds)\n",
        "precision_ai = precision_score(test_y, test_preds, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "precision_human = precision_score(test_y, test_preds, pos_label=0)  # Assuming \"AI\" is the positive class\n",
        "\n",
        "recall_ai = recall_score(test_y, test_preds, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "recall_human = recall_score(test_y, test_preds, pos_label=0)  # Assuming \"AI\" is the positive class\n",
        "\n",
        "f1_ai = f1_score(test_y, test_preds, pos_label=1)  # Assuming \"AI\" is the positive class\n",
        "f1_human = f1_score(test_y, test_preds, pos_label=0)  # Assuming \"AI\" is the positive class\n",
        "conf_matrix = confusion_matrix(test_y, test_preds)\n",
        "\n",
        "\n",
        "roc_auc = roc_auc_score(test_y, test_preds)\n",
        "print(test_y.numpy())\n",
        "print(test_preds)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision_ai)\n",
        "print(\"Precision:\", precision_human)\n",
        "\n",
        "print(\"Recall:\", recall_ai)\n",
        "print(\"Recall:\", recall_human)\n",
        "\n",
        "print(\"F1-Score:\", f1_ai)\n",
        "print(\"F1-Score:\", f1_human)\n",
        "\n",
        "print(\"ROC AUC:`\", roc_auc)"
      ],
      "metadata": {
        "id": "kxPyodHllWCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (replace with your actual values)\n",
        "ai_values = [precision_ai,recall_ai,f1_ai]\n",
        "human_values = [precision_human,recall_human,f1_human]\n",
        "\n",
        "# Metrics names\n",
        "metrics = [ 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "# Number of metrics\n",
        "num_metrics = len(metrics)\n",
        "\n",
        "# Create an array of indices for each metric\n",
        "indices = np.arange(num_metrics)\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.1\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "# Plot AI values\n",
        "ax.bar(indices, ai_values, bar_width, label='AI', color='blue',alpha=0.5)\n",
        "\n",
        "# Plot Human values\n",
        "ax.bar(indices + bar_width, human_values, bar_width, label='Human', color='orange')\n",
        "\n",
        "# Customize the plot\n",
        "ax.tick_params(axis='both', labelsize=15, labelcolor='black')\n",
        "\n",
        "# Make the axis labels (x and y) bold\n",
        "ax.xaxis.label.set_fontweight('bold')\n",
        "ax.yaxis.label.set_fontweight('bold')\n",
        "ax.set_xticks(indices + bar_width / 2)\n",
        "\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.set_ylabel('Metric Values')\n",
        "#ax.set_title('Comparison of AI and Human Performance Metrics')\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DTq5CiJbsIof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some text, true labels, and predictions\n",
        "for i in range(min(25, len(test_y))):  # Print the first 5 samples\n",
        "    print(f\"Text: {test_df['text'].iloc[i]}\")\n",
        "    print(f\"True Label: {test_df['label'].iloc[i]}, Predicted Label: {test_preds[i]}\")\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "id": "XPgwqzFtlzaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Plotting\n",
        "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
        "values = [tn, fp, fn, tp]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(labels, values, color=['pink', 'yellow', 'orange', 'blue'],alpha=0.8,width=0.3)\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Confusion Matrix')\n",
        "\n",
        "# Add value annotations on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "ax.tick_params(axis='y', labelsize=20, labelcolor='black')\n",
        "ax.set_xticklabels(labels, fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O7adlxhZWZhA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}