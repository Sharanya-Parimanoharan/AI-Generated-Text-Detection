{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XeM4-k48s24FDQQqKCQufKqii-KrN1ha",
      "authorship_tag": "ABX9TyOo6nw3XY9662xkkW4E2IWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharanya-Parimanoharan/AI-Generated-Text-Detection/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa9rMTxFFHc_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import random\n",
        "from sklearn.metrics import roc_curve, roc_auc_score,confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Fr2U8gtkFWTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "       torch.cuda.manual_seed_all(seed)\n",
        "\n"
      ],
      "metadata": {
        "id": "HByl0vNFFYxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "is_cuda = torch.cuda.is_available()\n",
        "##\n",
        "##\n",
        "###is_cuda = torch.cuda.is_available()\n",
        "##\n",
        "### If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "id": "9Ur_Hk49FbDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/data_2.csv\")\n",
        "print(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RHsvksTAFgEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X,y = df['text'].values,df['label'].values\n",
        "##startify is set to y to ensure that distribution of target variable is the same in the training and testing datasets\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
        "x=x_test.copy()\n",
        "y_t=y_test.copy()\n",
        "print(f'shape of train data is {x_train.shape}')\n",
        "print(f'shape of test data is {x_test.shape}')\n"
      ],
      "metadata": {
        "id": "DTw_nzayFoPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s\n",
        "\n",
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        try:\n",
        "            if len(review) != 0:\n",
        "                features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "        except ValueError as e:\n",
        "           # print(f\"Error processing review at index {ii}: {e}\")\n",
        "           # print(f\"Problematic review data: {review}\")\n",
        "            # Handle the error gracefully, e.g., by skipping this data point\n",
        "            continue\n",
        "    return features\n",
        "print(y_train)\n"
      ],
      "metadata": {
        "id": "9-stHUJOF1rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tockenize(x_train,y_train,x_val,y_val):\n",
        "    word_list = []\n",
        "\n",
        "\n",
        "    ##loop over each sentence in X_train and then loop over each word\n",
        "    for sent in x_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_string(word)\n",
        "            #if word not in stop_words and word != '':\n",
        "            word_list.append(word)\n",
        "\n",
        "    #Counter object of word_list is created, this object counts the frequency of word in word_list\n",
        "    corpus = Counter(word_list)\n",
        "    # sorting on the basis of most common words(by frequency) and select top 1000\n",
        "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
        "\n",
        "\n",
        "    # creating a dict-maps each word in corpus_ to an integer\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
        "\n",
        "    # tockenize\n",
        "    final_list_train,final_list_test = [],[]\n",
        "    #words integer value is added to the final_list_train\n",
        "    for sent in x_train:\n",
        "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "    for sent in x_val:\n",
        "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split()\n",
        "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
        "\n",
        "    #we have very less number of reviews with length > 500.\n",
        "    #So we will consideronly those below it.\n",
        "    final_list_train = padding_(final_list_train,500)\n",
        "    final_list_test = padding_(final_list_test,500)\n",
        "\n",
        "    encoded_train = [1 if label =='\"AI\"' else 0 for label in y_train]\n",
        "    encoded_test = [1 if label =='\"AI\"' else 0 for label in y_val]\n",
        "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n",
        "\n",
        "x_train_pad,y_train,x_test_pad,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)\n",
        "print(f'Length of vocabulary is {len(vocab)}')\n",
        "y__t=y_test.copy()\n",
        "print(y__t)\n"
      ],
      "metadata": {
        "id": "6xXbLjFcF2Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to generate bigrams from text and count their frequencies\n",
        "def generate_bigrams(text_data):\n",
        "    bigram_data = []\n",
        "    bigram_counter = Counter()  # Initialize a Counter to count bigram frequencies\n",
        "    for text in text_data:\n",
        "        tokens = text.split()\n",
        "        bigrams = [f\"{tokens[i]} {tokens[i+1]}\" for i in range(len(tokens) - 1)]\n",
        "        bigram_data.append(bigrams)\n",
        "        bigram_counter.update(bigrams)  # Update the bigram frequencies\n",
        "    return bigram_data, bigram_counter\n",
        "\n",
        "# Generate bigrams and count frequencies for training and testing data\n",
        "x_train_bigrams, bigram_counter_train = generate_bigrams(x_train)\n",
        "x_test_bigrams, bigram_counter_test = generate_bigrams(x_test)\n",
        "\n",
        "# Create a vocabulary for bigrams\n",
        "bigram_vocab = {bigram: i + len(vocab) + 1 for i, bigram in enumerate(bigram_counter_train.keys())}\n",
        "\n",
        "\n",
        "x_train_bigrams_pad = padding_(x_train_bigrams, 500)\n",
        "x_test_bigrams_pad = padding_(x_test_bigrams, 500)\n"
      ],
      "metadata": {
        "id": "aIM00d0UF7l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Assuming you have labels (y_train and y_test)\n",
        "\n",
        "# Extract indices for 'AI' and 'Human' labels in the training set\n",
        "indices_ai_train = [i for i, label in enumerate(y_train) if label == 1]\n",
        "indices_human_train = [i for i, label in enumerate(y_train) if label == 0]\n",
        "\n",
        "# Extract indices for 'AI' and 'Human' labels in the test set\n",
        "indices_ai_test = [i for i, label in enumerate(y_test) if label == 1]\n",
        "indices_human_test = [i for i, label in enumerate(y_test) if label == 0]\n",
        "\n",
        "# Count frequencies of bigrams for 'AI' and 'Human' in the training set\n",
        "bigram_counts_ai_train = Counter([bigram for sublist in x_train_bigrams_pad[indices_ai_train] for bigram in sublist])\n",
        "bigram_counts_human_train = Counter([bigram for sublist in x_train_bigrams_pad[indices_human_train] for bigram in sublist])\n",
        "\n",
        "# Count frequencies of bigrams for 'AI' and 'Human' in the test set\n",
        "bigram_counts_ai_test = Counter([bigram for sublist in x_test_bigrams_pad[indices_ai_test] for bigram in sublist])\n",
        "bigram_counts_human_test = Counter([bigram for sublist in x_test_bigrams_pad[indices_human_test] for bigram in sublist])\n",
        "\n",
        "# Plot bigram distribution for 'AI' and 'Human' in the training set\n",
        "bar_width = 0.35\n",
        "r1 = np.arange(len(bigram_counts_ai_train))\n",
        "r2 = [x + bar_width for x in r1]\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(r1, bigram_counts_ai_train.values(), color='blue', width=bar_width, edgecolor='grey', label='AI - Train')\n",
        "plt.bar(r2, bigram_counts_human_train.values(), color='orange', width=bar_width, edgecolor='grey', label='Human - Train')\n",
        "\n",
        "plt.title('Bigram Distribution - Training Set')\n",
        "plt.xlabel('Bigrams')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks([r + bar_width/2 for r in range(len(bigram_counts_ai_train))], bigram_counts_ai_train.keys(), rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot bigram distribution for 'AI' and 'Human' in the test set\n",
        "r1 = np.arange(len(bigram_counts_ai_test))\n",
        "r2 = [x + bar_width for x in r1]\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(r1, bigram_counts_ai_test.values(), color='blue', width=bar_width, edgecolor='grey', label='AI - Test')\n",
        "plt.bar(r2, bigram_counts_human_test.values(), color='orange', width=bar_width, edgecolor='grey', label='Human - Test')\n",
        "\n",
        "plt.title('Bigram Distribution - Test Set')\n",
        "plt.xlabel('Bigrams')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks([r + bar_width/2 for r in range(len(bigram_counts_ai_test))], bigram_counts_ai_test.keys(), rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "egnqmRBSEDXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create Tensor datasets from pytorch library\n",
        "#torch.from_numpy()- converts numpy array to  pytorch tensors\n",
        "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 25\n",
        "\n",
        "#Creates dataloader from pytorch library\n",
        "##data loader class used to load in to batches while training\n",
        "# make sure to SHUFFLE your data before each epoch\n",
        "train_loader = DataLoader(train_data, shuffle=False , batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "# sample_x and sample_y - input and otput data from the first batch of training\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample input: \\n', sample_y)\n"
      ],
      "metadata": {
        "id": "PnyQZ4vIGtEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationRNN(nn.Module):\n",
        "    def __init__(self,no_layers,vocab_size,bigram_vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
        "        super(TextClassificationRNN,self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "\n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "        self.bigram_vocab_size = bigram_vocab_size\n",
        "\n",
        "        # embedding and LSTM layers    converts tokenize words into dense vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        #initializes weights and biases internally\n",
        "        #lstm\n",
        "        #self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
        "                           #num_layers=no_layers,batch_first=True)\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm1 = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=1, batch_first=True)\n",
        "\n",
        "        # Embedding and LSTM layers for n-grams\n",
        "        self.bigram_embedding = nn.Embedding(bigram_vocab_size, embedding_dim)\n",
        "        self.bigram_lstm1 = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.bigram_lstm2 = nn.LSTM(input_size=hidden_dim, hidden_size=hidden_dim, num_layers=1, batch_first=True)\n",
        "\n",
        "\n",
        "\n",
        "        # Custom weight initialization\n",
        "        self.init_weights()\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # linear and sigmoid layer  -linear layers transforms lstm hidden states\n",
        "        self.fc = nn.Linear(2*self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "##        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "        for name, param in self.lstm1.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "        for name, param in self.lstm2.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "\n",
        "\n",
        "    def forward(self,x,hidden):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "        lstm_out1, _ = self.lstm1(embeds)\n",
        "        # LSTM layer 2\n",
        "        lstm_out2, _ = self.lstm2(lstm_out1)\n",
        "        # Flatten LSTM output\n",
        "        lstm_out2 = lstm_out2.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "\n",
        "        bigram_embeds = self.bigram_embedding(x)\n",
        "        bigram_lstm_out1, _ = self.bigram_lstm1(bigram_embeds)\n",
        "        bigram_lstm_out2, _ = self.bigram_lstm2(bigram_lstm_out1)\n",
        "        bigram_lstm_out2 = bigram_lstm_out2.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # Concatenate unigram and bigram representations\n",
        "        combined_representation = torch.cat((lstm_out2, bigram_lstm_out2), dim=1)\n",
        "\n",
        "        #print(embeds.shape)  #[50, 500, 1000]\n",
        "        #lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        #lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # dropout and fully connected layer\n",
        "       # out = self.dropout(lstm_out2)\n",
        "        out = self.dropout(combined_representation)\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "      #  sig_out = nn.functional.softmax(out, dim=1)\n",
        "\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "##        # softmax function\n",
        "##      #  softmax_out = F.softmax(out,dim=1)\n",
        "##\n",
        "##    #    # reshape to be batch_size first\n",
        "##        out = out.view(batch_size, -1)\n",
        "##        out = out[:, -1]  # get last batch of labels\n",
        "##\n",
        "##        # return last softmax output and hidden state\n",
        "##        return out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "4Oj6rsCdLHf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 2\n",
        "vocab_size = len(vocab)+1 #extra 1 for padding\n",
        "bigram_vocab_size= len(bigram_vocab) +1\n",
        "embedding_dim = 64\n",
        "output_dim = 2\n",
        "hidden_dim = 256\n",
        "\n",
        "\n",
        "model = TextClassificationRNN(no_layers,vocab_size,bigram_vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n"
      ],
      "metadata": {
        "id": "1plNyyKyLPOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#moving to gpu\n",
        "model.to(device)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# loss and optimization functions\n",
        "\n",
        "#learning rate\n",
        "lr=0.0001\n",
        "\n",
        "#loss function used for binary classification probelm\n",
        "##criterion = nn.BCELoss()\n",
        "criterion=nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "KOCrmvhJLSMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to predict accuracy\n",
        "#takes predicted value and true label, rounds off predicted value to nearest integer and compares it\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "metadata": {
        "id": "VQLD16rZLWjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5\n",
        "epochs = 5\n",
        "valid_loss_min = np.Inf\n",
        "# train for some number of epochs\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state\n",
        "    h = model.init_hidden(batch_size)\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        model.zero_grad()\n",
        "        output,h = model(inputs,h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "        # calculating accuracy\n",
        "        accuracy = acc(output,labels)\n",
        "        train_acc += accuracy\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "            accuracy = acc(output,labels)\n",
        "            val_acc += accuracy\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), 'textClassification.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')\n"
      ],
      "metadata": {
        "id": "Zyukdm8wLZZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (Your existing code)\n",
        "\n",
        "# After the training loop\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epoch_tr_loss, label='Training Loss')\n",
        "plt.plot(epoch_vl_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dm1MU3_3ajOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('textClassification.pt'))\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/textClassification.pt')\n"
      ],
      "metadata": {
        "id": "aVT4eJPCMEXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_text(text,threshold_facotor=0.1):\n",
        "        #each word is converted to integer using pretrained vocabulary vocab\n",
        "        word_seq = np.array([vocab[preprocess_string(word)] for word in text.split()\n",
        "                         if preprocess_string(word) in vocab.keys()])\n",
        "        word_seq = np.expand_dims(word_seq,axis=0)\n",
        "        pad =  torch.from_numpy(padding_(word_seq,500))\n",
        "        inputs = pad.to(device)\n",
        "        batch_size = inputs.shape[0]\n",
        "        h = model.init_hidden(batch_size)\n",
        "        h = tuple([each.data for each in h])\n",
        "        output, h = model(inputs, h)\n",
        "\n",
        "        # Assuming 'labels' are your true labels (ground truth)\n",
        "        true_labels = y_t\n",
        "\n",
        "    # Assuming 'output' is your predicted probabilities\n",
        "        predicted_probs = output.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ##return(output.item())\n",
        "       # print(output.item())\n",
        "      #  predicted_class= 1 if tput.item()>5.475988018588396e-06= else 0\n",
        "        return output.item()"
      ],
      "metadata": {
        "id": "Be5zKaRyMG4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "true_labels=[]\n",
        "predicted_labels=[]\n",
        "predicted_labelss=[]\n",
        "\n",
        "for i in range(len(x)):\n",
        "    pro=predict_text(x[i][1:-1])\n",
        "    predicted_labels.append(pro)\n",
        "    true_labels.append(y_t[i])\n",
        "\n",
        "    #status = '\"AI\"' if pro==1 else '\"Human\"'\n",
        "    #pro = (1 - pro) if status == '\"Human\"' else pro\n",
        "\n",
        "     # Calculate ROC curve\n",
        "pr, tpr, thresholds = roc_curve(y__t, predicted_labels)\n",
        "\n",
        "    # Calculate AUC\n",
        "auc_value = roc_auc_score(y__t, predicted_labels)\n",
        "\n",
        "        # Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(pr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_value:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "        # Choose threshold based on the ROC curve\n",
        "best_threshold_index = np.argmax(tpr - pr)\n",
        "best_threshold = thresholds[best_threshold_index]\n",
        "\n"
      ],
      "metadata": {
        "id": "U0n5g8TFMKQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for pro in predicted_labels:\n",
        "    # Apply the threshold\n",
        "    predicted_class = 1 if pro > best_threshold else 0\n",
        "    status = '\"AI\"' if predicted_class==1 else '\"Human\"'\n",
        "    predicted_labelss.append(status)\n",
        "\n",
        "\n",
        "print(true_labels)\n",
        "print('='*70)\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "id": "q59bZcLJMhNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(true_labels)\n",
        "print('=' * 70)\n",
        "print(predicted_labelss)"
      ],
      "metadata": {
        "id": "_QhTqkiPMhPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# Assuming true_labels and predicted_labels are your ground truth and predicted labels, respectively\n",
        "accuracy = accuracy_score(true_labels, predicted_labelss) *100\n",
        "precision = precision_score(true_labels, predicted_labelss, pos_label='\"AI\"')  # Assuming \"AI\" is the positive class\n",
        "recall = recall_score(true_labels, predicted_labelss, pos_label='\"AI\"')  # Assuming \"AI\" is the positive class\n",
        "f1 = f1_score(true_labels, predicted_labelss, pos_label='\"AI\"')  # Assuming \"AI\" is the positive class\n",
        "roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
        "confusion = confusion_matrix(true_labels, predicted_labelss, labels=['\"Human\"', '\"AI\"'])\n",
        "report = classification_report(true_labels, predicted_labelss)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "print(\"ROC AUC:`\", roc_auc)\n",
        "print(\"Confusion Matrix:\\n\", confusion)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "2LxnRsfONlNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/textClassification.pt'))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "new_df = pd.read_csv(\"drive/MyDrive/test.csv\")\n",
        "\n",
        "new_X, new_y = new_df['text'].values, new_df['label'].values\n",
        "n_y=new_y.copy()\n",
        "new_x_pad,new_y,new_x_pad,new_y,vocab = tockenize(new_X,new_y,new_X,new_y)\n",
        "new__y=new_y.copy()\n",
        "\n",
        "new_X_bigrams, bigram_counter_train = generate_bigrams(new_X)\n",
        "\n",
        "new_X_bigrams_pad = padding_(new_X_bigrams, 500)\n",
        "\n",
        "new_train_data = TensorDataset(torch.from_numpy(new_x_pad), torch.from_numpy(new_y))\n",
        "\n",
        "new_train_loader = DataLoader(new_train_data, shuffle=True , batch_size=batch_size)\n",
        "\n",
        "true_label=[]\n",
        "predicted_label=[]\n",
        "predicted_labels=[]\n",
        "\n",
        "for i in range(len(new_X)):\n",
        "    pro=predict_text(new_X[i][1:-1])\n",
        "    predicted_label.append(pro)\n",
        "    true_label.append(n_y[i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     # Calculate ROC curve\n",
        "pr, tpr, thresholds = roc_curve(new__y, predicted_label)\n",
        "\n",
        "    # Calculate AUC\n",
        "auc_value = roc_auc_score(new__y, predicted_label)\n",
        "\n",
        "        # Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(pr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_value:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for pro in predicted_label:\n",
        "    # Apply the threshold\n",
        "    predicted_class = 1 if pro > best_threshold else 0\n",
        "    status = '\"AI\"' if predicted_class==1 else '\"Human\"'\n",
        "    predicted_labels.append(status)\n",
        "\n",
        "accuracy = accuracy_score(true_label, predicted_labels) *100\n",
        "print(accuracy)\n",
        "print(n_y)\n",
        "print(predicted_labels)\n"
      ],
      "metadata": {
        "id": "6HNsT4Gpe7ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/textClassification.pt'))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "new_df = pd.read_csv(\"drive/MyDrive/test_new.csv\")\n",
        "\n",
        "new_X, new_y = new_df['text'].values, new_df['label'].values\n",
        "n_y=new_y.copy()\n",
        "new_x_pad,new_y,new_x_pad,new_y,vocab = tockenize(new_X,new_y,new_X,new_y)\n",
        "new__y=new_y.copy()\n",
        "\n",
        "new_X_bigrams, bigram_counter_train = generate_bigrams(new_X)\n",
        "\n",
        "new_X_bigrams_pad = padding_(new_X_bigrams, 500)\n",
        "\n",
        "new_train_data = TensorDataset(torch.from_numpy(new_x_pad), torch.from_numpy(new_y))\n",
        "\n",
        "new_train_loader = DataLoader(new_train_data, shuffle=True , batch_size=batch_size)\n",
        "\n",
        "true_label=[]\n",
        "predicted_label=[]\n",
        "predicted_labels=[]\n",
        "pred=[]\n",
        "\n",
        "for i in range(len(new_X)):\n",
        "    pro=predict_text(new_X[i][1:-1])\n",
        "    predicted_label.append(pro)\n",
        "    true_label.append(n_y[i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     # Calculate ROC curve\n",
        "pr, tpr, thresholds = roc_curve(new__y, predicted_label)\n",
        "\n",
        "    # Calculate AUC\n",
        "auc_value = roc_auc_score(new__y, predicted_label)\n",
        "\n",
        "        # Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(pr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_value:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "for pro in predicted_label:\n",
        "    # Apply the threshold\n",
        "    predicted_class = 1 if pro > best_threshold else 0\n",
        "    pred.append(predicted_class)\n",
        "    status = '\"AI\"' if predicted_class==1 else '\"Human\"'\n",
        "    predicted_labels.append(status)\n",
        "\n",
        "np.savetxt('/content/drive/MyDrive/pred_LSTM.csv', pred, delimiter=',',  fmt='%.2f')\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(true_label, predicted_labels) *100\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_label, predicted_labels)\n",
        "precision_ai = precision_score(true_label, predicted_labels, pos_label='\"AI\"')  # Assuming \"AI\" is the positive class\n",
        "precision_human = precision_score(true_label, predicted_labels, pos_label='\"Human\"')  # Assuming \"AI\" is the positive class\n",
        "\n",
        "recall_ai = recall_score(true_label, predicted_labels, pos_label='\"AI\"')  # Assuming \"AI\" is the positive class\n",
        "recall_human = recall_score(true_label, predicted_labels, pos_label='\"Human\"')  # Assuming \"AI\" is the positive class\n",
        "\n",
        "f1_ai = f1_score(true_label, predicted_labels, pos_label='\"AI\"')  # Assuming \"AI\" is the positive class\n",
        "f1_human = f1_score(true_label, predicted_labels, pos_label='\"Human\"')  # Assuming \"AI\" is the positive class\n",
        "\n",
        "conf_matrix = confusion_matrix(true_label, predicted_labels)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision_ai)\n",
        "print(\"Precision:\", precision_human)\n",
        "\n",
        "print(\"Recall:\", recall_ai)\n",
        "print(\"Recall:\", recall_human)\n",
        "\n",
        "print(\"F1-Score:\", f1_ai)\n",
        "print(\"F1-Score:\", f1_human)\n",
        "#print(n_y)\n",
        "#print(predicted_labels)"
      ],
      "metadata": {
        "id": "HSgVz1xQmFbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (replace with your actual values)\n",
        "ai_values = [precision_ai,recall_ai,f1_ai]\n",
        "human_values = [precision_human,recall_human,f1_human]\n",
        "\n",
        "# Metrics names\n",
        "metrics = [ 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "# Number of metrics\n",
        "num_metrics = len(metrics)\n",
        "\n",
        "# Create an array of indices for each metric\n",
        "indices = np.arange(num_metrics)\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.1\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "# Plot AI values\n",
        "ax.bar(indices, ai_values, bar_width, label='AI', color='blue',alpha=0.5)\n",
        "\n",
        "# Plot Human values\n",
        "ax.bar(indices + bar_width, human_values, bar_width, label='Human', color='orange')\n",
        "\n",
        "# Customize the plot\n",
        "# Make the y-axis tick labels darker and bigger\n",
        "ax.tick_params(axis='both', labelsize=15, labelcolor='black')\n",
        "\n",
        "# Make the axis labels (x and y) bold\n",
        "ax.xaxis.label.set_fontweight('bold')\n",
        "ax.yaxis.label.set_fontweight('bold')\n",
        "ax.set_xticks(indices + bar_width / 2)\n",
        "\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend(fontsize=9)\n",
        "ax.set_ylabel('Metric Values')\n",
        "#ax.set_title('Comparison of AI and Human Performance Metrics')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gXqc7ix2wdBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Plotting\n",
        "labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
        "values = [tn, fp, fn, tp]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(labels, values, color=['pink', 'yellow', 'orange', 'blue'],alpha=0.8,width=0.3)\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Confusion Matrix')\n",
        "\n",
        "# Add value annotations on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "ax.tick_params(axis='y', labelsize=20, labelcolor='black')\n",
        "ax.set_xticklabels(labels, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iCQtsWY6VGms"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}